"""
Swarm Orchestrator - æ™ºèƒ½ä½“èœ‚ç¾¤è°ƒåº¦å™¨æ ¸å¿ƒå®ç°

èŒè´£ï¼š
1. ä»»åŠ¡è§£æ - ç†è§£ç”¨æˆ·æ„å›¾ï¼Œæå–æ ¸å¿ƒç›®æ ‡
2. ä»»åŠ¡åˆ†è§£ - å°†å¤æ‚ä»»åŠ¡æ‹†è§£ä¸ºå¯å¹¶è¡Œæ‰§è¡Œçš„å­ä»»åŠ¡
3. ä¾èµ–åˆ†æ - è¯†åˆ«ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼Œæ„å»º DAG
4. ä»»åŠ¡åˆ†å‘ - å°†ä»»åŠ¡åˆ†å‘ç»™åˆé€‚çš„ Worker
5. è¿›åº¦ç›‘æ§ - å®æ—¶è¿½è¸ªæ‰€æœ‰ Worker æ‰§è¡ŒçŠ¶æ€
6. ç»“æœæ•´åˆ - æ”¶é›†å¹¶æ•´åˆæ‰€æœ‰ Worker è¾“å‡º
"""

import json
import os
import time
import uuid
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum
from typing import Any, Optional
from pathlib import Path


class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRYING = "retrying"


class TaskPriority(Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


class WorkerType(Enum):
    RESEARCHER = "researcher"
    CODER = "coder"
    TESTER = "tester"
    WRITER = "writer"
    REVIEWER = "reviewer"


@dataclass
class SubTask:
    task_id: str
    description: str
    worker_type: str
    dependencies: list[str]
    priority: str
    status: str = "pending"
    worker_id: Optional[str] = None
    created_at: Optional[str] = None
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    result_file: Optional[str] = None
    error: Optional[str] = None
    input_data: dict = None
    expected_output: dict = None

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now().isoformat()
        if self.input_data is None:
            self.input_data = {}
        if self.expected_output is None:
            self.expected_output = {}


@dataclass
class TaskAnalysis:
    core_goal: str
    task_type: str
    complexity: str
    swarm_mode: bool
    reasoning: str


class SwarmOrchestrator:
    SWARM_DIR = ".trae/swarm"
    QUEUE_FILE = "queue.json"
    STATUS_FILE = "status.json"
    RESULTS_DIR = "results"

    def __init__(self, project_path: str = "."):
        self.project_path = Path(project_path)
        self.swarm_path = self.project_path / self.SWARM_DIR
        self.queue_path = self.swarm_path / self.QUEUE_FILE
        self.status_path = self.swarm_path / self.STATUS_FILE
        self.results_path = self.swarm_path / self.RESULTS_DIR
        
        self._ensure_directories()

    def _ensure_directories(self):
        self.swarm_path.mkdir(parents=True, exist_ok=True)
        self.results_path.mkdir(parents=True, exist_ok=True)

    def _generate_task_id(self) -> str:
        return f"task_{uuid.uuid4().hex[:8]}"

    def _generate_main_task_id(self) -> str:
        return f"main_{uuid.uuid4().hex[:8]}"

    def analyze_task(self, user_request: str) -> TaskAnalysis:
        keywords_complex = [
            "ç³»ç»Ÿ", "æ¶æ„", "é‡æ„", "å¼€å‘", "å®ç°",
            "é›†æˆ", "éƒ¨ç½²", "æµ‹è¯•å¥—ä»¶", "æ–‡æ¡£ç³»ç»Ÿ"
        ]
        keywords_simple = [
            "ä¿®æ”¹", "ä¿®å¤", "ä¼˜åŒ–", "æ·»åŠ ", "æ›´æ–°"
        ]
        
        complexity_score = 0
        for kw in keywords_complex:
            if kw in user_request:
                complexity_score += 2
        
        for kw in keywords_simple:
            if kw in user_request:
                complexity_score += 1
        
        if complexity_score >= 4:
            complexity = "complex"
            swarm_mode = True
        elif complexity_score >= 2:
            complexity = "medium"
            swarm_mode = "å¹¶è¡Œ" in user_request or "åŒæ—¶" in user_request
        else:
            complexity = "simple"
            swarm_mode = False

        task_type = "development"
        if "æµ‹è¯•" in user_request:
            task_type = "test"
        elif "æ–‡æ¡£" in user_request:
            task_type = "docs"
        elif "è°ƒç ”" in user_request or "ç ”ç©¶" in user_request:
            task_type = "research"
        elif "é‡æ„" in user_request:
            task_type = "refactor"

        return TaskAnalysis(
            core_goal=user_request,
            task_type=task_type,
            complexity=complexity,
            swarm_mode=swarm_mode,
            reasoning=f"å¤æ‚åº¦è¯„åˆ†: {complexity_score}, ä»»åŠ¡ç±»å‹: {task_type}"
        )

    def decompose_task(self, analysis: TaskAnalysis) -> list[SubTask]:
        tasks = []
        
        if analysis.task_type == "development":
            tasks = [
                SubTask(
                    task_id=self._generate_task_id(),
                    description="è°ƒç ”æŠ€æœ¯æ–¹æ¡ˆå’Œæœ€ä½³å®è·µ",
                    worker_type=WorkerType.RESEARCHER.value,
                    dependencies=[],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="è®¾è®¡ç³»ç»Ÿæ¶æ„å’Œæ•°æ®æ¨¡å‹",
                    worker_type=WorkerType.CODER.value,
                    dependencies=[tasks[0].task_id] if tasks else [],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="å®ç°æ ¸å¿ƒåŠŸèƒ½ä»£ç ",
                    worker_type=WorkerType.CODER.value,
                    dependencies=[tasks[1].task_id] if len(tasks) > 1 else [],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="ç¼–å†™å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•",
                    worker_type=WorkerType.TESTER.value,
                    dependencies=[tasks[2].task_id] if len(tasks) > 2 else [],
                    priority=TaskPriority.MEDIUM.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="ç¼–å†™ API æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜",
                    worker_type=WorkerType.WRITER.value,
                    dependencies=[tasks[2].task_id] if len(tasks) > 2 else [],
                    priority=TaskPriority.MEDIUM.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="ä»£ç å®¡æŸ¥å’Œè´¨é‡æ£€æŸ¥",
                    worker_type=WorkerType.REVIEWER.value,
                    dependencies=[t.task_id for t in tasks[2:4]] if len(tasks) > 3 else [],
                    priority=TaskPriority.MEDIUM.value
                ),
            ]
        
        elif analysis.task_type == "refactor":
            tasks = [
                SubTask(
                    task_id=self._generate_task_id(),
                    description="åˆ†æç°æœ‰ä»£ç ç»“æ„",
                    worker_type=WorkerType.RESEARCHER.value,
                    dependencies=[],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="è®¾è®¡é‡æ„æ–¹æ¡ˆ",
                    worker_type=WorkerType.CODER.value,
                    dependencies=[tasks[0].task_id],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="æ‰§è¡Œä»£ç é‡æ„",
                    worker_type=WorkerType.CODER.value,
                    dependencies=[tasks[1].task_id],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="éªŒè¯é‡æ„ç»“æœ",
                    worker_type=WorkerType.TESTER.value,
                    dependencies=[tasks[2].task_id],
                    priority=TaskPriority.MEDIUM.value
                ),
            ]
        
        elif analysis.task_type == "test":
            tasks = [
                SubTask(
                    task_id=self._generate_task_id(),
                    description="åˆ†ææµ‹è¯•éœ€æ±‚",
                    worker_type=WorkerType.RESEARCHER.value,
                    dependencies=[],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="ç¼–å†™æµ‹è¯•ç”¨ä¾‹",
                    worker_type=WorkerType.TESTER.value,
                    dependencies=[tasks[0].task_id],
                    priority=TaskPriority.HIGH.value
                ),
                SubTask(
                    task_id=self._generate_task_id(),
                    description="æ‰§è¡Œæµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š",
                    worker_type=WorkerType.TESTER.value,
                    dependencies=[tasks[1].task_id],
                    priority=TaskPriority.MEDIUM.value
                ),
            ]
        
        else:
            tasks = [
                SubTask(
                    task_id=self._generate_task_id(),
                    description=f"æ‰§è¡Œä»»åŠ¡: {analysis.core_goal}",
                    worker_type=WorkerType.CODER.value,
                    dependencies=[],
                    priority=TaskPriority.MEDIUM.value
                ),
            ]
        
        return tasks

    def build_dag(self, tasks: list[SubTask]) -> dict[str, list[str]]:
        dag = {}
        for task in tasks:
            dag[task.task_id] = task.dependencies
        return dag

    def get_execution_order(self, dag: dict[str, list[str]]) -> list[list[str]]:
        in_degree = {node: 0 for node in dag}
        for node, deps in dag.items():
            for dep in deps:
                if dep in in_degree:
                    pass
        
        for node, deps in dag.items():
            in_degree[node] = len([d for d in deps if d in dag])
        
        levels = []
        remaining = set(dag.keys())
        
        while remaining:
            ready = [n for n in remaining if in_degree[n] == 0]
            if not ready:
                break
            
            levels.append(ready)
            remaining -= set(ready)
            
            for node in remaining:
                in_degree[node] = len([d for d in dag[node] if d in remaining])
        
        return levels

    def create_queue(self, main_task_id: str, tasks: list[SubTask], dag: dict[str, list[str]]) -> dict:
        queue_data = {
            "version": "1.0",
            "created_at": datetime.now().isoformat(),
            "main_task_id": main_task_id,
            "tasks": {task.task_id: asdict(task) for task in tasks},
            "dag": dag,
            "execution_order": self.get_execution_order(dag)
        }
        
        with open(self.queue_path, 'w', encoding='utf-8') as f:
            json.dump(queue_data, f, ensure_ascii=False, indent=2)
        
        return queue_data

    def read_queue(self) -> dict:
        if not self.queue_path.exists():
            return {}
        
        with open(self.queue_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def update_task_status(self, task_id: str, status: str, **kwargs):
        queue = self.read_queue()
        if task_id in queue.get("tasks", {}):
            queue["tasks"][task_id]["status"] = status
            queue["tasks"][task_id].update(kwargs)
            
            with open(self.queue_path, 'w', encoding='utf-8') as f:
                json.dump(queue, f, ensure_ascii=False, indent=2)

    def get_ready_tasks(self) -> list[dict]:
        queue = self.read_queue()
        if not queue:
            return []
        
        ready_tasks = []
        completed_tasks = {
            tid for tid, t in queue["tasks"].items() 
            if t["status"] == "completed"
        }
        
        for task_id, task in queue["tasks"].items():
            if task["status"] != "pending":
                continue
            
            deps = task.get("dependencies", [])
            if all(d in completed_tasks for d in deps):
                ready_tasks.append(task)
        
        return ready_tasks

    def get_progress(self) -> dict:
        queue = self.read_queue()
        if not queue:
            return {"total": 0, "completed": 0, "running": 0, "pending": 0, "failed": 0}
        
        tasks = queue.get("tasks", {})
        status_counts = {"total": len(tasks)}
        
        for status in ["completed", "running", "pending", "failed"]:
            status_counts[status] = sum(1 for t in tasks.values() if t.get("status") == status)
        
        status_counts["progress_percent"] = (
            status_counts["completed"] / status_counts["total"] * 100 
            if status_counts["total"] > 0 else 0
        )
        
        return status_counts

    def save_result(self, task_id: str, worker_id: str, output: dict, 
                    execution_time: float, tokens_used: int = 0):
        result = {
            "task_id": task_id,
            "worker_id": worker_id,
            "status": "completed",
            "output": output,
            "execution_time": execution_time,
            "tokens_used": tokens_used,
            "completed_at": datetime.now().isoformat()
        }
        
        result_file = self.results_path / f"{task_id}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        self.update_task_status(
            task_id, 
            "completed",
            worker_id=worker_id,
            result_file=str(result_file),
            completed_at=datetime.now().isoformat()
        )

    def aggregate_results(self) -> dict:
        queue = self.read_queue()
        if not queue:
            return {"status": "no_tasks", "results": {}}
        
        results = {}
        for task_id, task in queue["tasks"].items():
            if task["status"] == "completed" and task.get("result_file"):
                result_path = Path(task["result_file"])
                if result_path.exists():
                    with open(result_path, 'r', encoding='utf-8') as f:
                        results[task_id] = json.load(f)
        
        progress = self.get_progress()
        
        final_status = "success"
        if progress["failed"] > 0:
            final_status = "partial" if progress["completed"] > 0 else "failed"
        
        return {
            "status": final_status,
            "main_task_id": queue.get("main_task_id"),
            "progress": progress,
            "results": results,
            "summary": self._generate_summary(results)
        }

    def _generate_summary(self, results: dict) -> str:
        if not results:
            return "æ— æ‰§è¡Œç»“æœ"
        
        summary_parts = []
        for task_id, result in results.items():
            output = result.get("output", {})
            summary = output.get("summary", "å·²å®Œæˆ")
            summary_parts.append(f"- {task_id}: {summary}")
        
        return "\n".join(summary_parts)

    def execute(self, user_request: str) -> dict:
        print(f"ğŸ” ä»»åŠ¡åˆ†æä¸­...")
        analysis = self.analyze_task(user_request)
        print(f"   æ ¸å¿ƒç›®æ ‡: {analysis.core_goal}")
        print(f"   å¤æ‚åº¦: {analysis.complexity}")
        print(f"   èœ‚ç¾¤æ¨¡å¼: {analysis.swarm_mode}")
        
        if not analysis.swarm_mode:
            print(f"   â­ï¸ ç®€å•ä»»åŠ¡ï¼Œè·³è¿‡èœ‚ç¾¤æ¨¡å¼")
            return {
                "status": "simple_task",
                "analysis": asdict(analysis),
                "message": "ä»»åŠ¡ç®€å•ï¼Œå»ºè®®ç›´æ¥æ‰§è¡Œ"
            }
        
        print(f"\nğŸ“‹ ä»»åŠ¡åˆ†è§£ä¸­...")
        tasks = self.decompose_task(analysis)
        print(f"   åˆ†è§£ä¸º {len(tasks)} ä¸ªå­ä»»åŠ¡:")
        for i, task in enumerate(tasks, 1):
            deps = f" (ä¾èµ–: {', '.join(task.dependencies)})" if task.dependencies else ""
            print(f"   {i}. [{task.worker_type}] {task.description}{deps}")
        
        print(f"\nğŸ”— æ„å»ºä¾èµ–å›¾...")
        dag = self.build_dag(tasks)
        execution_order = self.get_execution_order(dag)
        print(f"   æ‰§è¡Œå±‚çº§: {len(execution_order)} å±‚")
        for i, level in enumerate(execution_order, 1):
            print(f"   å±‚çº§ {i}: {len(level)} ä¸ªä»»åŠ¡å¯å¹¶è¡Œ")
        
        main_task_id = self._generate_main_task_id()
        print(f"\nğŸ“ åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—...")
        queue = self.create_queue(main_task_id, tasks, dag)
        print(f"   ä¸»ä»»åŠ¡ ID: {main_task_id}")
        print(f"   é˜Ÿåˆ—æ–‡ä»¶: {self.queue_path}")
        
        return {
            "status": "ready",
            "main_task_id": main_task_id,
            "analysis": asdict(analysis),
            "tasks": [asdict(t) for t in tasks],
            "dag": dag,
            "execution_order": execution_order,
            "queue_file": str(self.queue_path),
            "message": "ä»»åŠ¡å·²åˆ†è§£ï¼Œç­‰å¾… Worker æ‰§è¡Œ"
        }


def main():
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python orchestrator.py <ç”¨æˆ·è¯·æ±‚>")
        print("ç¤ºä¾‹: python orchestrator.py 'å¼€å‘ä¸€ä¸ªç”¨æˆ·è®¤è¯ç³»ç»Ÿ'")
        return
    
    user_request = " ".join(sys.argv[1:])
    
    orchestrator = SwarmOrchestrator()
    result = orchestrator.execute(user_request)
    
    print(f"\n{'='*50}")
    print(f"æ‰§è¡Œç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
